{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea1075ac-5858-4dce-ba92-af4a80cc0f1a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:AliceBlue; padding:10px; border-left:5px solid #6495ed; margin-bottom:10px;\">\n",
    "  <h4 style=\"font-size:13px;\">üì¶ <strong>Importar Librerias</strong></h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46f46562-7bf6-44ae-9b72-b6e5cd98246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import ray\n",
    "from ray import serve\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from fastapi import FastAPI\n",
    "from fastapi import Request\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "from fastapi.exceptions import RequestValidationError\n",
    "from fastapi.responses import JSONResponse\n",
    "from starlette.requests import Request\n",
    "from json import JSONDecodeError\n",
    "from sklearn.datasets import load_iris\n",
    "#import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40b92d1-7b5e-4967-bfab-e63a93b2ef39",
   "metadata": {},
   "source": [
    "<div style=\"background-color:AliceBlue; padding:10px; border-left:5px solid #2e8b57; margin-bottom:10px;\">\n",
    "  <h4 style=\"font-size:13px;\">ü§ñ <strong>Configuracion del Modelo</strong></h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c285e1-8cbd-4c19-986d-ed70ef1affd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    class Item(BaseModel):\n",
    "        model_config = ConfigDict(extra=\"forbid\")\n",
    "        c1: float\n",
    "        c2: float\n",
    "        c3: float\n",
    "        c4: float\n",
    "\n",
    "    app = FastAPI(\n",
    "        title=\"Import Predictor API\",\n",
    "        description=\"Import Pipeline online inference\",\n",
    "    )\n",
    "\n",
    "    @app.exception_handler(RequestValidationError)\n",
    "    async def validation_exception_handler(request: Request, exc: RequestValidationError):\n",
    "        mensajes = [err[\"msg\"] for err in exc.errors()]\n",
    "        return JSONResponse(\n",
    "            status_code=422,\n",
    "            content={\n",
    "                \"cod\": 422,\n",
    "                \"msg\": \"; \".join(mensajes),\n",
    "                \"data\": None,\n",
    "                \"errors\": exc.errors(),\n",
    "            },\n",
    "        )\n",
    "\n",
    "    @serve.deployment(ray_actor_options={\"num_cpus\": 0.1})\n",
    "    @serve.ingress(app)\n",
    "    class ModelMlFlow:\n",
    "        def __init__(self, model_uri: str):\n",
    "            mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "            try:\n",
    "                self.model = mlflow.pyfunc.load_model(model_uri)\n",
    "                #self.model = mlflow.sklearn.load_model(model_uri)\n",
    "            except Exception as ex:\n",
    "                print(f\"MlFlow: Se produjo el siguiente error : {ex} \")\n",
    "\n",
    "        @app.post(\"/\")\n",
    "        async def score(self, item: dict):  # <- evitar pickling de 'Item'\n",
    "            try:\n",
    "                #payload = item\n",
    "                #df = pd.DataFrame([payload])\n",
    "                #score = self.model.predict(df)\n",
    "                #score_value = float(score.iloc[0])\n",
    "                df = pd.DataFrame([item])\n",
    "                score_value = float(self.model.predict(df).iat[0])\n",
    "                return {\n",
    "                    \"cod\": 200,\n",
    "                    \"msg\": \"Score calculated successfully.\",\n",
    "                    \"data\": {\"em_eventprobability\": score_value},\n",
    "                    \"errors\": None,\n",
    "                }\n",
    "            except Exception as e:\n",
    "                return {\n",
    "                    \"cod\": 500,\n",
    "                    \"msg\": \"Error calculating score\",\n",
    "                    \"data\": None,\n",
    "                    \"errors\": str(e),\n",
    "                }\n",
    "\n",
    "except Exception as ex:\n",
    "    print(f\"Desployment y Ingress: Se produjo el siguiente error : {ex} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a3a91f-f16e-456c-baad-f4ce0a224ad9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color:AliceBlue; padding:10px; border-left:5px solid #2e8b57; margin-bottom:10px;\">\n",
    "  <h4 style=\"font-size:13px;\">ü§ñ <strong>Conecta a un cluster de Ray ya iniciado</strong></h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b0fe7a2-50f6-4ca4-96fa-566140a1a623",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 20:52:16,219\tINFO client_builder.py:244 -- Passing the following kwargs to ray.init() on the server: log_to_driver\n",
      "SIGTERM handler is not set because current thread is not the main thread.\n",
      "INFO 2025-08-21 20:52:20,309 serve 18912 -- Connecting to existing Serve app in namespace \"serve\". New http options will not be applied.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conectado a Ray existente.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ray.init(address=\"ray://127.0.0.1:10001\")\n",
    "    serve.start(detached=True, http_options={\"host\": \"0.0.0.0\", \"port\": 8000})\n",
    "    print(\"‚úÖ Conectado a Ray existente.\")\n",
    "except Exception as e:\n",
    "    sys.exit(f\"‚ùå No se pudo conectar a ray://127.0.0.1:10001 ‚Üí {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8229594-8572-452e-b01b-cf5f66f684ef",
   "metadata": {},
   "source": [
    "<div style=\"background-color:AliceBlue; padding:10px; border-left:5px solid #2e8b57; margin-bottom:10px;\">\n",
    "  <h4 style=\"font-size:13px;\">ü§ñ <strong>Desplegar el Modelo</strong></h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53b74bc8-2973-4898-9f58-ef6fbf552c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2025-08-21 20:52:20,321 serve 18912 -- Connecting to existing Serve app in namespace \"serve\". New http options will not be applied.\n",
      "WARNING 2025-08-21 20:52:20,321 serve 18912 -- The new client HTTP config differs from the existing one in the following fields: ['host', 'location']. The new HTTP config is ignored.\n",
      "INFO 2025-08-21 20:52:23,391 serve 18912 -- Application 'model-pyfunc' is ready at http://0.0.0.0:8000/v1/model-pyfunc.\n",
      "INFO 2025-08-21 20:52:23,391 serve 18912 -- Deployed app 'model-pyfunc' successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Listo en http://127.0.0.1:8000/v1/model-pyfunc\n"
     ]
    }
   ],
   "source": [
    "MODEL_URI = \"models:/model-pyfunc/1\"   # o \"models:/iris-models/Production\"\n",
    "NAME = \"model-pyfunc\"\n",
    "ROUTE_PREFIX = \"/v1/model-pyfunc\"\n",
    "\n",
    "graph = ModelMlFlow.bind(MODEL_URI)\n",
    "\n",
    "try:\n",
    "    serve.run(graph, name=NAME, route_prefix=ROUTE_PREFIX)\n",
    "    print(f\"‚úÖ Listo en http://127.0.0.1:8000{ROUTE_PREFIX}\")\n",
    "except Exception as ex:\n",
    "    print(f\"Desployment y Ingress: Se produjo el siguiente error : {ex}\")\n",
    "    try:\n",
    "        serve.delete(NAME)\n",
    "        print(f\"üßπ App '{NAME}' eliminada por fallo de deploy.\")\n",
    "    except Exception as cleanup_ex:\n",
    "        print(f\"‚ö†Ô∏è No se pudo eliminar '{NAME}': {cleanup_ex}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f846fcd-d197-46ec-a534-45cae7385512",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30230b68-e453-46de-8f56-258ee7142895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
