{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea1075ac-5858-4dce-ba92-af4a80cc0f1a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:AliceBlue; padding:10px; border-left:5px solid #6495ed; margin-bottom:10px;\">\n",
    "  <h4 style=\"font-size:13px;\">üì¶ <strong>Importar Librerias</strong></h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46f46562-7bf6-44ae-9b72-b6e5cd98246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import serve\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from fastapi import FastAPI\n",
    "from fastapi import Request\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "from fastapi.exceptions import RequestValidationError\n",
    "from fastapi.responses import JSONResponse\n",
    "from starlette.requests import Request\n",
    "from json import JSONDecodeError\n",
    "from sklearn.datasets import load_iris\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a3a91f-f16e-456c-baad-f4ce0a224ad9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background-color:AliceBlue; padding:10px; border-left:5px solid #2e8b57; margin-bottom:10px;\">\n",
    "  <h4 style=\"font-size:13px;\">ü§ñ <strong>Conecta a un cluster de Ray ya iniciado</strong></h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b0fe7a2-50f6-4ca4-96fa-566140a1a623",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 19:53:22,532\tINFO client_builder.py:242 -- Passing the following kwargs to ray.init() on the server: log_to_driver\n",
      "SIGTERM handler is not set because current thread is not the main thread.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conectado a Ray existente.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ray.init(address=\"ray://127.0.0.1:10001\")\n",
    "    print(\"‚úÖ Conectado a Ray existente.\")\n",
    "except Exception as e:\n",
    "    sys.exit(f\"‚ùå No se pudo conectar a ray://127.0.0.1:10001 ‚Üí {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40b92d1-7b5e-4967-bfab-e63a93b2ef39",
   "metadata": {},
   "source": [
    "<div style=\"background-color:AliceBlue; padding:10px; border-left:5px solid #2e8b57; margin-bottom:10px;\">\n",
    "  <h4 style=\"font-size:13px;\">ü§ñ <strong>Configuracion del Modelo</strong></h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd1d9551-0b49-40c2-9f75-bf135cb1c320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    app = FastAPI(\n",
    "        title = \"Import Predictor API\",\n",
    "        description = \"Import Pipeline online inference\"\n",
    "    )\n",
    "\n",
    "    @app.exception_handler(RequestValidationError)\n",
    "    async def validation_exception_handler(request: Request, exc: RequestValidationError):\n",
    "        mensajes = [err[\"msg\"] for err in exc.errors()]\n",
    "        return JSONResponse(\n",
    "            status_code = 422,\n",
    "            content = { \"cod\": 422, \"msg\": \"; \".join(mensajes), \"data\": None, \"errors\": exc.errors(), },\n",
    "        )\n",
    "    \n",
    "    class Item(BaseModel):\n",
    "\n",
    "        model_config = ConfigDict(extra='forbid')\n",
    "        \n",
    "        sepal_length: float\n",
    "        sepal_width:  float\n",
    "        petal_length: float\n",
    "        petal_width:  float\n",
    "\n",
    "    @serve.deployment( num_replicas=1, ray_actor_options={\"num_cpus\": 1} )\n",
    "    \n",
    "    @serve.ingress(app)\n",
    "    class ModelMlFlow:\n",
    "        def __init__(self, model_uri: str):\n",
    "            mlflow.set_tracking_uri(\"http://127.0.0.1:8080/\")\n",
    "            try:\n",
    "                self.model = mlflow.sklearn.load_model(model_uri)\n",
    "            except Exception as ex:\n",
    "                print(f\"MlFlow: Se produjo el siguiente error : {ex} \")\n",
    "\n",
    "        @app.post(\"/\")\n",
    "        async def score(self, item: Item):\n",
    "            try:\n",
    "                #payload = item.dict()\n",
    "                payload = item.model_dump()\n",
    "                df = pd.DataFrame([payload])\n",
    "                score = float(self.model.predict_proba(df)[0][1])\n",
    "                return {\"cod\": 200, \"msg\": \"Score calculated successfully.\", \"data\": {\"em_eventprobability\": score}, \"errors\": None }\n",
    "            except Exception as e:\n",
    "                #logger.error(f\"Error in import prediction: {e}\")\n",
    "                return {\"cod\": 500, \"msg\": \"Error calculating score\", \"data\": None, \"errors\": str(e)}\n",
    "except Exception as ex:\n",
    "    print(f\"Desployment y Ingress: Se produjo el siguiente error : {ex} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8229594-8572-452e-b01b-cf5f66f684ef",
   "metadata": {},
   "source": [
    "<div style=\"background-color:AliceBlue; padding:10px; border-left:5px solid #2e8b57; margin-bottom:10px;\">\n",
    "  <h4 style=\"font-size:13px;\">ü§ñ <strong>Desplegar el Modelo</strong></h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53b74bc8-2973-4898-9f58-ef6fbf552c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2025-08-10 19:53:26,616 serve 28664 -- Connecting to existing Serve app in namespace \"serve\". New http options will not be applied.\n",
      "INFO 2025-08-10 19:53:30,688 serve 28664 -- Application 'iris-models-v1' is ready at http://127.0.0.1:8000/v1/iris-models/score.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Listo en http://127.0.0.1:8000/v1/iris-models/score\n"
     ]
    }
   ],
   "source": [
    "MODEL_URI = \"models:/iris-models/1\"   # o \"models:/iris-models/Production\"\n",
    "NAME = \"iris-models-v1\"\n",
    "ROUTE_PREFIX = \"/v1/iris-models/score\"\n",
    "\n",
    "graph = ModelMlFlow.bind(MODEL_URI)\n",
    "\n",
    "try:\n",
    "    #serve.delete(NAME)  # opcional: limpiar antes\n",
    "    serve.run(graph, name=NAME, route_prefix=ROUTE_PREFIX)\n",
    "    print(f\"‚úÖ Listo en http://127.0.0.1:8000{ROUTE_PREFIX}\")\n",
    "except Exception as ex:\n",
    "    print(f\"Desployment y Ingress: Se produjo el siguiente error : {ex}\")\n",
    "    try:\n",
    "        serve.delete(NAME)\n",
    "        print(f\"üßπ App '{NAME}' eliminada por fallo de deploy.\")\n",
    "    except Exception as cleanup_ex:\n",
    "        print(f\"‚ö†Ô∏è No se pudo eliminar '{NAME}': {cleanup_ex}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f846fcd-d197-46ec-a534-45cae7385512",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
